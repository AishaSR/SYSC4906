{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jrgreen7/SYSC4906/blob/master/Lecture_15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPpwjWIUbLKK",
        "colab_type": "text"
      },
      "source": [
        "#Sequence-to-sequence LSTM Model\n",
        "- From https://github.com/lukas/ml-class/blob/master/videos/seq2seq/train.py\n",
        "- Which awas from https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbxaRmRObH-L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "26afc7d5-02dd-4d6e-b33d-0d3fd7254696"
      },
      "source": [
        "# adapted from https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html\n",
        "\n",
        "#!pip install wandb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, TimeDistributed, RepeatVector, Dense\n",
        "import numpy as np\n",
        "#import wandb\n",
        "#from wandb.keras import WandbCallback\n",
        "\n",
        "#wandb.init()  # See https://pypi.org/project/wandb/. Like TensorBoard\n",
        "#config = wandb.config\n",
        "\n",
        "\n",
        "class CharacterTable(object):\n",
        "    \"\"\"Given a set of characters:\n",
        "    + Encode them to a one hot integer representation\n",
        "    + Decode the one hot integer representation to their character output\n",
        "    + Decode a vector of probabilities to their character output\n",
        "    \"\"\"\n",
        "    def __init__(self, chars):\n",
        "        \"\"\"Initialize character table.\n",
        "        # Arguments\n",
        "            chars: Characters that can appear in the input.\n",
        "        \"\"\"\n",
        "        self.chars = sorted(set(chars))\n",
        "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
        "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
        "\n",
        "    def encode(self, C, num_rows):\n",
        "        \"\"\"One hot encode given string C.\n",
        "        # Arguments\n",
        "            num_rows: Number of rows in the returned one hot encoding. This is\n",
        "                used to keep the # of rows for each data the same.\n",
        "        \"\"\"\n",
        "        x = np.zeros((num_rows, len(self.chars)))\n",
        "        for i, c in enumerate(C):\n",
        "            x[i, self.char_indices[c]] = 1\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, calc_argmax=True):\n",
        "        if calc_argmax:\n",
        "            x = x.argmax(axis=-1)\n",
        "        return ''.join(self.indices_char[x] for x in x)\n",
        "\n",
        "# Parameters for the model and dataset.\n",
        "__training_size = 50000\n",
        "__digits = 5\n",
        "__hidden_size = 128\n",
        "__batch_size = 128\n",
        "\n",
        "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
        "# int is DIGITS.\n",
        "maxlen = __digits + 1 + __digits\n",
        "\n",
        "# All the numbers, plus sign and space for padding.\n",
        "chars = '0123456789+- '\n",
        "ctable = CharacterTable(chars)\n",
        "\n",
        "questions = []\n",
        "expected = []\n",
        "seen = set()\n",
        "print('Generating data...')\n",
        "while len(questions) < __training_size:\n",
        "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
        "                    for i in range(np.random.randint(1, __digits + 1))))\n",
        "    a, b = f(), f()\n",
        "    # Skip any addition questions we've already seen\n",
        "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
        "    key = tuple(sorted((a, b)))\n",
        "    if key in seen:\n",
        "        continue\n",
        "    seen.add(key)\n",
        "    # Pad the data with spaces such that it is always MAXLEN.\n",
        "    q = '{}-{}'.format(a, b)\n",
        "    query = q + ' ' * (maxlen - len(q))\n",
        "    ans = str(a - b)\n",
        "    # Answers can be of maximum size DIGITS + 1.\n",
        "    ans += ' ' * (__digits + 1 - len(ans))\n",
        "\n",
        "    questions.append(query)\n",
        "    expected.append(ans)\n",
        "    \n",
        "print('Total addition questions:', len(questions))\n",
        "\n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(questions), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(questions), __digits + 1, len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(questions):\n",
        "    x[i] = ctable.encode(sentence, maxlen)\n",
        "for i, sentence in enumerate(expected):\n",
        "    y[i] = ctable.encode(sentence, __digits + 1)\n",
        "\n",
        "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
        "# digits.\n",
        "indices = np.arange(len(y))\n",
        "np.random.shuffle(indices)\n",
        "x = x[indices]\n",
        "y = y[indices]\n",
        "\n",
        "# Explicitly set apart 10% for validation data that we never train over.\n",
        "split_at = len(x) - len(x) // 10\n",
        "(x_train, x_val) = x[:split_at], x[split_at:]\n",
        "(y_train, y_val) = y[:split_at], y[split_at:]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(__hidden_size, input_shape=(maxlen, len(chars))))\n",
        "model.add(RepeatVector(__digits + 1))\n",
        "model.add(LSTM(__hidden_size, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(len(chars), activation='softmax')))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Train the model each generation and show predictions against the validation\n",
        "# dataset.\n",
        "for iteration in range(1, 200):\n",
        "    print()\n",
        "    print('-' * 50)\n",
        "    print('Iteration', iteration)\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=__batch_size,\n",
        "              epochs=1,\n",
        "              validation_data=(x_val, y_val))\n",
        "#              validation_data=(x_val, y_val),callbacks=[WandbCallback()])\n",
        "    # Select 10 samples from the validation set at random so we can visualize\n",
        "    # errors.\n",
        "    for i in range(10):\n",
        "        ind = np.random.randint(0, len(x_val))\n",
        "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
        "        preds = model.predict_classes(rowx, verbose=0)\n",
        "        q = ctable.decode(rowx[0])\n",
        "        correct = ctable.decode(rowy[0])\n",
        "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
        "        print('Q', q, end=' ')\n",
        "        print('T', correct, end=' ')\n",
        "        if correct == guess:\n",
        "            print('☑', end=' ')\n",
        "        else:\n",
        "            print('☒', end=' ')\n",
        "        print(guess)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating data...\n",
            "Total addition questions: 50000\n",
            "Vectorization...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 128)               72704     \n",
            "_________________________________________________________________\n",
            "repeat_vector_1 (RepeatVecto (None, 6, 128)            0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 6, 128)            131584    \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 6, 13)             1677      \n",
            "=================================================================\n",
            "Total params: 205,965\n",
            "Trainable params: 205,965\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "45000/45000 [==============================] - 20s 437us/step - loss: 1.8234 - acc: 0.3602 - val_loss: 1.6235 - val_acc: 0.4038\n",
            "Q 35-3883     T -3848  ☒ -8888 \n",
            "Q 3850-3354   T 496    ☒ -3333 \n",
            "Q 839-85396   T -84557 ☒ -48888\n",
            "Q 768-99489   T -98721 ☒ -88888\n",
            "Q 16-52585    T -52569 ☒ -88848\n",
            "Q 0-949       T -949   ☒ -488  \n",
            "Q 18-1800     T -1782  ☒ -1808 \n",
            "Q 8232-85081  T -76849 ☒ -13033\n",
            "Q 65-731      T -666   ☒ -188  \n",
            "Q 6-737       T -731   ☒ -888  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 2\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 14s 315us/step - loss: 1.5685 - acc: 0.4182 - val_loss: 1.5241 - val_acc: 0.4361\n",
            "Q 57-97259    T -97202 ☒ -77777\n",
            "Q 2774-1      T 2773   ☒ 1117  \n",
            "Q 71-1903     T -1832  ☒ -117  \n",
            "Q 70-301      T -231   ☒ -11   \n",
            "Q 66331-3189  T 63142  ☒ 11117 \n",
            "Q 30-61908    T -61878 ☒ -70778\n",
            "Q 12-39       T -27    ☒ -1    \n",
            "Q 4483-304    T 4179   ☒ 4444  \n",
            "Q 70-999      T -929   ☒ -888  \n",
            "Q 79753-474   T 79279  ☒ 88877 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 3\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 14s 301us/step - loss: 1.4924 - acc: 0.4469 - val_loss: 1.4503 - val_acc: 0.4568\n",
            "Q 88485-54152 T 34333  ☒ 8877  \n",
            "Q 48582-696   T 47886  ☒ 45565 \n",
            "Q 63-705      T -642   ☒ -677  \n",
            "Q 46-96       T -50    ☒ -66   \n",
            "Q 58833-99450 T -40617 ☒ -3227 \n",
            "Q 14849-8306  T 6543   ☒ -327  \n",
            "Q 9550-49511  T -39961 ☒ -55505\n",
            "Q 82023-9     T 82014  ☒ 82222 \n",
            "Q 9112-276    T 8836   ☒ 1129  \n",
            "Q 0-8322      T -8322  ☒ -3222 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 4\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 14s 319us/step - loss: 1.4161 - acc: 0.4698 - val_loss: 1.3643 - val_acc: 0.4833\n",
            "Q 66-5120     T -5054  ☒ -5103 \n",
            "Q 494-2       T 492    ☒ 442   \n",
            "Q 151-4758    T -4607  ☒ -5433 \n",
            "Q 97560-3     T 97557  ☒ 99555 \n",
            "Q 61616-50    T 61566  ☒ 66155 \n",
            "Q 26642-9457  T 17185  ☒ 22443 \n",
            "Q 656-521     T 135    ☒ 51    \n",
            "Q 58926-99655 T -40729 ☒ -5233 \n",
            "Q 3129-2      T 3127   ☒ 2225  \n",
            "Q 81-2546     T -2465  ☒ -5133 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 5\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "10880/45000 [======>.......................] - ETA: 9s - loss: 1.3665 - acc: 0.4892"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}